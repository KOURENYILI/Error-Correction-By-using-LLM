{
  "best_metric": 0.13690055906772614,
  "best_model_checkpoint": "wsj/checkpoint-400",
  "epoch": 1.382886776145203,
  "eval_steps": 100,
  "global_step": 400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03457216940363008,
      "grad_norm": 0.9907282590866089,
      "learning_rate": 2e-05,
      "loss": 1.8601,
      "step": 10
    },
    {
      "epoch": 0.06914433880726016,
      "grad_norm": 1.2141627073287964,
      "learning_rate": 4e-05,
      "loss": 2.0884,
      "step": 20
    },
    {
      "epoch": 0.10371650821089023,
      "grad_norm": 1.75996732711792,
      "learning_rate": 6e-05,
      "loss": 2.1985,
      "step": 30
    },
    {
      "epoch": 0.13828867761452032,
      "grad_norm": 1.3769193887710571,
      "learning_rate": 8e-05,
      "loss": 2.0919,
      "step": 40
    },
    {
      "epoch": 0.17286084701815038,
      "grad_norm": 2.67435884475708,
      "learning_rate": 0.0001,
      "loss": 2.3578,
      "step": 50
    },
    {
      "epoch": 0.20743301642178047,
      "grad_norm": 0.5522788763046265,
      "learning_rate": 0.00012,
      "loss": 0.8693,
      "step": 60
    },
    {
      "epoch": 0.24200518582541056,
      "grad_norm": 0.4029791057109833,
      "learning_rate": 0.00014,
      "loss": 0.5295,
      "step": 70
    },
    {
      "epoch": 0.27657735522904064,
      "grad_norm": 0.22140678763389587,
      "learning_rate": 0.00016,
      "loss": 0.3363,
      "step": 80
    },
    {
      "epoch": 0.3111495246326707,
      "grad_norm": 0.1841510683298111,
      "learning_rate": 0.00018,
      "loss": 0.2322,
      "step": 90
    },
    {
      "epoch": 0.34572169403630076,
      "grad_norm": 0.31985488533973694,
      "learning_rate": 0.0002,
      "loss": 0.2286,
      "step": 100
    },
    {
      "epoch": 0.34572169403630076,
      "eval_loss": 0.25413596630096436,
      "eval_runtime": 11.2132,
      "eval_samples_per_second": 45.66,
      "eval_steps_per_second": 5.708,
      "step": 100
    },
    {
      "epoch": 0.3802938634399309,
      "grad_norm": 0.14755673706531525,
      "learning_rate": 0.0001992831541218638,
      "loss": 0.3097,
      "step": 110
    },
    {
      "epoch": 0.41486603284356094,
      "grad_norm": 0.13271167874336243,
      "learning_rate": 0.00019856630824372762,
      "loss": 0.2639,
      "step": 120
    },
    {
      "epoch": 0.449438202247191,
      "grad_norm": 0.16308167576789856,
      "learning_rate": 0.00019784946236559142,
      "loss": 0.2157,
      "step": 130
    },
    {
      "epoch": 0.4840103716508211,
      "grad_norm": 0.14124096930027008,
      "learning_rate": 0.0001971326164874552,
      "loss": 0.1979,
      "step": 140
    },
    {
      "epoch": 0.5185825410544511,
      "grad_norm": 0.22106005251407623,
      "learning_rate": 0.00019641577060931903,
      "loss": 0.1796,
      "step": 150
    },
    {
      "epoch": 0.5531547104580813,
      "grad_norm": 0.13787893950939178,
      "learning_rate": 0.0001956989247311828,
      "loss": 0.2491,
      "step": 160
    },
    {
      "epoch": 0.5877268798617113,
      "grad_norm": 0.13810373842716217,
      "learning_rate": 0.0001949820788530466,
      "loss": 0.2103,
      "step": 170
    },
    {
      "epoch": 0.6222990492653414,
      "grad_norm": 0.1488470435142517,
      "learning_rate": 0.00019426523297491038,
      "loss": 0.1996,
      "step": 180
    },
    {
      "epoch": 0.6568712186689715,
      "grad_norm": 0.14719989895820618,
      "learning_rate": 0.00019354838709677422,
      "loss": 0.1774,
      "step": 190
    },
    {
      "epoch": 0.6914433880726015,
      "grad_norm": 0.37895554304122925,
      "learning_rate": 0.000192831541218638,
      "loss": 0.1525,
      "step": 200
    },
    {
      "epoch": 0.6914433880726015,
      "eval_loss": 0.17497561872005463,
      "eval_runtime": 11.219,
      "eval_samples_per_second": 45.637,
      "eval_steps_per_second": 5.705,
      "step": 200
    },
    {
      "epoch": 0.7260155574762316,
      "grad_norm": 0.13803938031196594,
      "learning_rate": 0.0001921146953405018,
      "loss": 0.2192,
      "step": 210
    },
    {
      "epoch": 0.7605877268798618,
      "grad_norm": 0.16714058816432953,
      "learning_rate": 0.0001913978494623656,
      "loss": 0.1969,
      "step": 220
    },
    {
      "epoch": 0.7951598962834918,
      "grad_norm": 0.1564909815788269,
      "learning_rate": 0.0001906810035842294,
      "loss": 0.1833,
      "step": 230
    },
    {
      "epoch": 0.8297320656871219,
      "grad_norm": 0.17892757058143616,
      "learning_rate": 0.0001899641577060932,
      "loss": 0.1493,
      "step": 240
    },
    {
      "epoch": 0.8643042350907519,
      "grad_norm": 0.3615484833717346,
      "learning_rate": 0.000189247311827957,
      "loss": 0.1458,
      "step": 250
    },
    {
      "epoch": 0.898876404494382,
      "grad_norm": 0.17339672148227692,
      "learning_rate": 0.0001885304659498208,
      "loss": 0.2065,
      "step": 260
    },
    {
      "epoch": 0.9334485738980121,
      "grad_norm": 0.16788224875926971,
      "learning_rate": 0.0001878136200716846,
      "loss": 0.1752,
      "step": 270
    },
    {
      "epoch": 0.9680207433016422,
      "grad_norm": 0.14618238806724548,
      "learning_rate": 0.0001870967741935484,
      "loss": 0.166,
      "step": 280
    },
    {
      "epoch": 1.0025929127052722,
      "grad_norm": 0.6790130734443665,
      "learning_rate": 0.0001863799283154122,
      "loss": 0.1565,
      "step": 290
    },
    {
      "epoch": 1.0371650821089022,
      "grad_norm": 0.16976338624954224,
      "learning_rate": 0.000185663082437276,
      "loss": 0.1923,
      "step": 300
    },
    {
      "epoch": 1.0371650821089022,
      "eval_loss": 0.15091872215270996,
      "eval_runtime": 32.7819,
      "eval_samples_per_second": 15.618,
      "eval_steps_per_second": 1.952,
      "step": 300
    },
    {
      "epoch": 1.0717372515125323,
      "grad_norm": 0.12104398757219315,
      "learning_rate": 0.00018494623655913978,
      "loss": 0.1828,
      "step": 310
    },
    {
      "epoch": 1.1063094209161626,
      "grad_norm": 0.12625087797641754,
      "learning_rate": 0.0001842293906810036,
      "loss": 0.1603,
      "step": 320
    },
    {
      "epoch": 1.1408815903197926,
      "grad_norm": 0.20911741256713867,
      "learning_rate": 0.00018351254480286738,
      "loss": 0.1567,
      "step": 330
    },
    {
      "epoch": 1.1754537597234227,
      "grad_norm": 0.13324372470378876,
      "learning_rate": 0.0001827956989247312,
      "loss": 0.129,
      "step": 340
    },
    {
      "epoch": 1.2100259291270528,
      "grad_norm": 0.14079585671424866,
      "learning_rate": 0.000182078853046595,
      "loss": 0.1886,
      "step": 350
    },
    {
      "epoch": 1.2445980985306828,
      "grad_norm": 0.16042180359363556,
      "learning_rate": 0.0001813620071684588,
      "loss": 0.1733,
      "step": 360
    },
    {
      "epoch": 1.2791702679343129,
      "grad_norm": 0.16367019712924957,
      "learning_rate": 0.00018064516129032257,
      "loss": 0.1462,
      "step": 370
    },
    {
      "epoch": 1.313742437337943,
      "grad_norm": 0.16483931243419647,
      "learning_rate": 0.0001799283154121864,
      "loss": 0.1283,
      "step": 380
    },
    {
      "epoch": 1.348314606741573,
      "grad_norm": 0.2594800293445587,
      "learning_rate": 0.00017921146953405018,
      "loss": 0.1265,
      "step": 390
    },
    {
      "epoch": 1.382886776145203,
      "grad_norm": 0.1620560586452484,
      "learning_rate": 0.00017849462365591398,
      "loss": 0.1795,
      "step": 400
    },
    {
      "epoch": 1.382886776145203,
      "eval_loss": 0.13690055906772614,
      "eval_runtime": 33.1849,
      "eval_samples_per_second": 15.429,
      "eval_steps_per_second": 1.929,
      "step": 400
    }
  ],
  "logging_steps": 10,
  "max_steps": 2890,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.404907180798771e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
