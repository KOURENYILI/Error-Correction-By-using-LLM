{
  "best_metric": 0.1089109554886818,
  "best_model_checkpoint": "wsj/checkpoint-900",
  "epoch": 3.111495246326707,
  "eval_steps": 100,
  "global_step": 900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03457216940363008,
      "grad_norm": 0.9907282590866089,
      "learning_rate": 2e-05,
      "loss": 1.8601,
      "step": 10
    },
    {
      "epoch": 0.06914433880726016,
      "grad_norm": 1.2141627073287964,
      "learning_rate": 4e-05,
      "loss": 2.0884,
      "step": 20
    },
    {
      "epoch": 0.10371650821089023,
      "grad_norm": 1.75996732711792,
      "learning_rate": 6e-05,
      "loss": 2.1985,
      "step": 30
    },
    {
      "epoch": 0.13828867761452032,
      "grad_norm": 1.3769193887710571,
      "learning_rate": 8e-05,
      "loss": 2.0919,
      "step": 40
    },
    {
      "epoch": 0.17286084701815038,
      "grad_norm": 2.67435884475708,
      "learning_rate": 0.0001,
      "loss": 2.3578,
      "step": 50
    },
    {
      "epoch": 0.20743301642178047,
      "grad_norm": 0.5522788763046265,
      "learning_rate": 0.00012,
      "loss": 0.8693,
      "step": 60
    },
    {
      "epoch": 0.24200518582541056,
      "grad_norm": 0.4029791057109833,
      "learning_rate": 0.00014,
      "loss": 0.5295,
      "step": 70
    },
    {
      "epoch": 0.27657735522904064,
      "grad_norm": 0.22140678763389587,
      "learning_rate": 0.00016,
      "loss": 0.3363,
      "step": 80
    },
    {
      "epoch": 0.3111495246326707,
      "grad_norm": 0.1841510683298111,
      "learning_rate": 0.00018,
      "loss": 0.2322,
      "step": 90
    },
    {
      "epoch": 0.34572169403630076,
      "grad_norm": 0.31985488533973694,
      "learning_rate": 0.0002,
      "loss": 0.2286,
      "step": 100
    },
    {
      "epoch": 0.34572169403630076,
      "eval_loss": 0.25413596630096436,
      "eval_runtime": 11.2132,
      "eval_samples_per_second": 45.66,
      "eval_steps_per_second": 5.708,
      "step": 100
    },
    {
      "epoch": 0.3802938634399309,
      "grad_norm": 0.14755673706531525,
      "learning_rate": 0.0001992831541218638,
      "loss": 0.3097,
      "step": 110
    },
    {
      "epoch": 0.41486603284356094,
      "grad_norm": 0.13271167874336243,
      "learning_rate": 0.00019856630824372762,
      "loss": 0.2639,
      "step": 120
    },
    {
      "epoch": 0.449438202247191,
      "grad_norm": 0.16308167576789856,
      "learning_rate": 0.00019784946236559142,
      "loss": 0.2157,
      "step": 130
    },
    {
      "epoch": 0.4840103716508211,
      "grad_norm": 0.14124096930027008,
      "learning_rate": 0.0001971326164874552,
      "loss": 0.1979,
      "step": 140
    },
    {
      "epoch": 0.5185825410544511,
      "grad_norm": 0.22106005251407623,
      "learning_rate": 0.00019641577060931903,
      "loss": 0.1796,
      "step": 150
    },
    {
      "epoch": 0.5531547104580813,
      "grad_norm": 0.13787893950939178,
      "learning_rate": 0.0001956989247311828,
      "loss": 0.2491,
      "step": 160
    },
    {
      "epoch": 0.5877268798617113,
      "grad_norm": 0.13810373842716217,
      "learning_rate": 0.0001949820788530466,
      "loss": 0.2103,
      "step": 170
    },
    {
      "epoch": 0.6222990492653414,
      "grad_norm": 0.1488470435142517,
      "learning_rate": 0.00019426523297491038,
      "loss": 0.1996,
      "step": 180
    },
    {
      "epoch": 0.6568712186689715,
      "grad_norm": 0.14719989895820618,
      "learning_rate": 0.00019354838709677422,
      "loss": 0.1774,
      "step": 190
    },
    {
      "epoch": 0.6914433880726015,
      "grad_norm": 0.37895554304122925,
      "learning_rate": 0.000192831541218638,
      "loss": 0.1525,
      "step": 200
    },
    {
      "epoch": 0.6914433880726015,
      "eval_loss": 0.17497561872005463,
      "eval_runtime": 11.219,
      "eval_samples_per_second": 45.637,
      "eval_steps_per_second": 5.705,
      "step": 200
    },
    {
      "epoch": 0.7260155574762316,
      "grad_norm": 0.13803938031196594,
      "learning_rate": 0.0001921146953405018,
      "loss": 0.2192,
      "step": 210
    },
    {
      "epoch": 0.7605877268798618,
      "grad_norm": 0.16714058816432953,
      "learning_rate": 0.0001913978494623656,
      "loss": 0.1969,
      "step": 220
    },
    {
      "epoch": 0.7951598962834918,
      "grad_norm": 0.1564909815788269,
      "learning_rate": 0.0001906810035842294,
      "loss": 0.1833,
      "step": 230
    },
    {
      "epoch": 0.8297320656871219,
      "grad_norm": 0.17892757058143616,
      "learning_rate": 0.0001899641577060932,
      "loss": 0.1493,
      "step": 240
    },
    {
      "epoch": 0.8643042350907519,
      "grad_norm": 0.3615484833717346,
      "learning_rate": 0.000189247311827957,
      "loss": 0.1458,
      "step": 250
    },
    {
      "epoch": 0.898876404494382,
      "grad_norm": 0.17339672148227692,
      "learning_rate": 0.0001885304659498208,
      "loss": 0.2065,
      "step": 260
    },
    {
      "epoch": 0.9334485738980121,
      "grad_norm": 0.16788224875926971,
      "learning_rate": 0.0001878136200716846,
      "loss": 0.1752,
      "step": 270
    },
    {
      "epoch": 0.9680207433016422,
      "grad_norm": 0.14618238806724548,
      "learning_rate": 0.0001870967741935484,
      "loss": 0.166,
      "step": 280
    },
    {
      "epoch": 1.0025929127052722,
      "grad_norm": 0.6790130734443665,
      "learning_rate": 0.0001863799283154122,
      "loss": 0.1565,
      "step": 290
    },
    {
      "epoch": 1.0371650821089022,
      "grad_norm": 0.16976338624954224,
      "learning_rate": 0.000185663082437276,
      "loss": 0.1923,
      "step": 300
    },
    {
      "epoch": 1.0371650821089022,
      "eval_loss": 0.15091872215270996,
      "eval_runtime": 32.7819,
      "eval_samples_per_second": 15.618,
      "eval_steps_per_second": 1.952,
      "step": 300
    },
    {
      "epoch": 1.0717372515125323,
      "grad_norm": 0.12104398757219315,
      "learning_rate": 0.00018494623655913978,
      "loss": 0.1828,
      "step": 310
    },
    {
      "epoch": 1.1063094209161626,
      "grad_norm": 0.12625087797641754,
      "learning_rate": 0.0001842293906810036,
      "loss": 0.1603,
      "step": 320
    },
    {
      "epoch": 1.1408815903197926,
      "grad_norm": 0.20911741256713867,
      "learning_rate": 0.00018351254480286738,
      "loss": 0.1567,
      "step": 330
    },
    {
      "epoch": 1.1754537597234227,
      "grad_norm": 0.13324372470378876,
      "learning_rate": 0.0001827956989247312,
      "loss": 0.129,
      "step": 340
    },
    {
      "epoch": 1.2100259291270528,
      "grad_norm": 0.14079585671424866,
      "learning_rate": 0.000182078853046595,
      "loss": 0.1886,
      "step": 350
    },
    {
      "epoch": 1.2445980985306828,
      "grad_norm": 0.16042180359363556,
      "learning_rate": 0.0001813620071684588,
      "loss": 0.1733,
      "step": 360
    },
    {
      "epoch": 1.2791702679343129,
      "grad_norm": 0.16367019712924957,
      "learning_rate": 0.00018064516129032257,
      "loss": 0.1462,
      "step": 370
    },
    {
      "epoch": 1.313742437337943,
      "grad_norm": 0.16483931243419647,
      "learning_rate": 0.0001799283154121864,
      "loss": 0.1283,
      "step": 380
    },
    {
      "epoch": 1.348314606741573,
      "grad_norm": 0.2594800293445587,
      "learning_rate": 0.00017921146953405018,
      "loss": 0.1265,
      "step": 390
    },
    {
      "epoch": 1.382886776145203,
      "grad_norm": 0.1620560586452484,
      "learning_rate": 0.00017849462365591398,
      "loss": 0.1795,
      "step": 400
    },
    {
      "epoch": 1.382886776145203,
      "eval_loss": 0.13690055906772614,
      "eval_runtime": 33.1849,
      "eval_samples_per_second": 15.429,
      "eval_steps_per_second": 1.929,
      "step": 400
    },
    {
      "epoch": 1.4174589455488331,
      "grad_norm": 0.18305347859859467,
      "learning_rate": 0.00017777777777777779,
      "loss": 0.1661,
      "step": 410
    },
    {
      "epoch": 1.4520311149524634,
      "grad_norm": 0.17671069502830505,
      "learning_rate": 0.0001770609318996416,
      "loss": 0.1522,
      "step": 420
    },
    {
      "epoch": 1.4866032843560935,
      "grad_norm": 0.2422553151845932,
      "learning_rate": 0.0001763440860215054,
      "loss": 0.1342,
      "step": 430
    },
    {
      "epoch": 1.5211754537597235,
      "grad_norm": 0.28758469223976135,
      "learning_rate": 0.00017562724014336917,
      "loss": 0.129,
      "step": 440
    },
    {
      "epoch": 1.5557476231633536,
      "grad_norm": 0.1343555450439453,
      "learning_rate": 0.000174910394265233,
      "loss": 0.1731,
      "step": 450
    },
    {
      "epoch": 1.5903197925669836,
      "grad_norm": 0.12750230729579926,
      "learning_rate": 0.00017419354838709678,
      "loss": 0.1581,
      "step": 460
    },
    {
      "epoch": 1.6248919619706137,
      "grad_norm": 0.18028199672698975,
      "learning_rate": 0.00017347670250896058,
      "loss": 0.1534,
      "step": 470
    },
    {
      "epoch": 1.6594641313742438,
      "grad_norm": 0.19946512579917908,
      "learning_rate": 0.00017275985663082438,
      "loss": 0.1338,
      "step": 480
    },
    {
      "epoch": 1.6940363007778738,
      "grad_norm": 0.19135929644107819,
      "learning_rate": 0.0001720430107526882,
      "loss": 0.1061,
      "step": 490
    },
    {
      "epoch": 1.7286084701815039,
      "grad_norm": 0.14309100806713104,
      "learning_rate": 0.00017132616487455196,
      "loss": 0.1668,
      "step": 500
    },
    {
      "epoch": 1.7286084701815039,
      "eval_loss": 0.1264881044626236,
      "eval_runtime": 32.7426,
      "eval_samples_per_second": 15.637,
      "eval_steps_per_second": 1.955,
      "step": 500
    },
    {
      "epoch": 1.763180639585134,
      "grad_norm": 0.1989244669675827,
      "learning_rate": 0.00017060931899641577,
      "loss": 0.145,
      "step": 510
    },
    {
      "epoch": 1.797752808988764,
      "grad_norm": 0.17411097884178162,
      "learning_rate": 0.00016989247311827957,
      "loss": 0.1404,
      "step": 520
    },
    {
      "epoch": 1.832324978392394,
      "grad_norm": 0.22678467631340027,
      "learning_rate": 0.00016917562724014338,
      "loss": 0.1331,
      "step": 530
    },
    {
      "epoch": 1.8668971477960241,
      "grad_norm": 0.21379689872264862,
      "learning_rate": 0.00016845878136200718,
      "loss": 0.1132,
      "step": 540
    },
    {
      "epoch": 1.9014693171996542,
      "grad_norm": 0.1589822769165039,
      "learning_rate": 0.00016774193548387098,
      "loss": 0.1668,
      "step": 550
    },
    {
      "epoch": 1.9360414866032842,
      "grad_norm": 0.1858605444431305,
      "learning_rate": 0.00016702508960573479,
      "loss": 0.1508,
      "step": 560
    },
    {
      "epoch": 1.9706136560069143,
      "grad_norm": 0.18468812108039856,
      "learning_rate": 0.00016630824372759856,
      "loss": 0.1305,
      "step": 570
    },
    {
      "epoch": 2.0051858254105444,
      "grad_norm": 0.20674997568130493,
      "learning_rate": 0.0001655913978494624,
      "loss": 0.1336,
      "step": 580
    },
    {
      "epoch": 2.0397579948141744,
      "grad_norm": 0.14865423738956451,
      "learning_rate": 0.00016487455197132617,
      "loss": 0.1452,
      "step": 590
    },
    {
      "epoch": 2.0743301642178045,
      "grad_norm": 0.11810127645730972,
      "learning_rate": 0.00016415770609318997,
      "loss": 0.1316,
      "step": 600
    },
    {
      "epoch": 2.0743301642178045,
      "eval_loss": 0.12203250825405121,
      "eval_runtime": 11.2813,
      "eval_samples_per_second": 45.385,
      "eval_steps_per_second": 5.673,
      "step": 600
    },
    {
      "epoch": 2.1089023336214345,
      "grad_norm": 0.15524710714817047,
      "learning_rate": 0.00016344086021505378,
      "loss": 0.1412,
      "step": 610
    },
    {
      "epoch": 2.1434745030250646,
      "grad_norm": 0.17562024295330048,
      "learning_rate": 0.00016272401433691758,
      "loss": 0.1172,
      "step": 620
    },
    {
      "epoch": 2.178046672428695,
      "grad_norm": 0.20849725604057312,
      "learning_rate": 0.00016200716845878136,
      "loss": 0.1088,
      "step": 630
    },
    {
      "epoch": 2.212618841832325,
      "grad_norm": 0.14193134009838104,
      "learning_rate": 0.00016129032258064516,
      "loss": 0.1492,
      "step": 640
    },
    {
      "epoch": 2.247191011235955,
      "grad_norm": 0.1601204127073288,
      "learning_rate": 0.00016057347670250896,
      "loss": 0.1418,
      "step": 650
    },
    {
      "epoch": 2.2817631806395853,
      "grad_norm": 0.14481939375400543,
      "learning_rate": 0.00015985663082437277,
      "loss": 0.1322,
      "step": 660
    },
    {
      "epoch": 2.3163353500432153,
      "grad_norm": 0.14912089705467224,
      "learning_rate": 0.00015913978494623657,
      "loss": 0.1108,
      "step": 670
    },
    {
      "epoch": 2.3509075194468454,
      "grad_norm": 0.2382522076368332,
      "learning_rate": 0.00015842293906810038,
      "loss": 0.0955,
      "step": 680
    },
    {
      "epoch": 2.3854796888504755,
      "grad_norm": 0.1586449295282364,
      "learning_rate": 0.00015770609318996418,
      "loss": 0.1532,
      "step": 690
    },
    {
      "epoch": 2.4200518582541055,
      "grad_norm": 0.15658827126026154,
      "learning_rate": 0.00015698924731182796,
      "loss": 0.1363,
      "step": 700
    },
    {
      "epoch": 2.4200518582541055,
      "eval_loss": 0.11725915968418121,
      "eval_runtime": 11.5416,
      "eval_samples_per_second": 44.361,
      "eval_steps_per_second": 5.545,
      "step": 700
    },
    {
      "epoch": 2.4546240276577356,
      "grad_norm": 0.14713285863399506,
      "learning_rate": 0.0001562724014336918,
      "loss": 0.1262,
      "step": 710
    },
    {
      "epoch": 2.4891961970613656,
      "grad_norm": 0.15218161046504974,
      "learning_rate": 0.00015555555555555556,
      "loss": 0.1132,
      "step": 720
    },
    {
      "epoch": 2.5237683664649957,
      "grad_norm": 0.2123243808746338,
      "learning_rate": 0.00015483870967741937,
      "loss": 0.11,
      "step": 730
    },
    {
      "epoch": 2.5583405358686258,
      "grad_norm": 0.15959039330482483,
      "learning_rate": 0.00015412186379928314,
      "loss": 0.1489,
      "step": 740
    },
    {
      "epoch": 2.592912705272256,
      "grad_norm": 0.14033855497837067,
      "learning_rate": 0.00015340501792114697,
      "loss": 0.1341,
      "step": 750
    },
    {
      "epoch": 2.627484874675886,
      "grad_norm": 0.17532344162464142,
      "learning_rate": 0.00015268817204301075,
      "loss": 0.1283,
      "step": 760
    },
    {
      "epoch": 2.662057044079516,
      "grad_norm": 0.2063031792640686,
      "learning_rate": 0.00015197132616487455,
      "loss": 0.1076,
      "step": 770
    },
    {
      "epoch": 2.696629213483146,
      "grad_norm": 0.19763138890266418,
      "learning_rate": 0.00015125448028673836,
      "loss": 0.1146,
      "step": 780
    },
    {
      "epoch": 2.731201382886776,
      "grad_norm": 0.17619936168193817,
      "learning_rate": 0.00015053763440860216,
      "loss": 0.1469,
      "step": 790
    },
    {
      "epoch": 2.765773552290406,
      "grad_norm": 0.13055089116096497,
      "learning_rate": 0.00014982078853046594,
      "loss": 0.138,
      "step": 800
    },
    {
      "epoch": 2.765773552290406,
      "eval_loss": 0.11212262511253357,
      "eval_runtime": 12.3154,
      "eval_samples_per_second": 41.574,
      "eval_steps_per_second": 5.197,
      "step": 800
    },
    {
      "epoch": 2.800345721694036,
      "grad_norm": 0.16790838539600372,
      "learning_rate": 0.00014910394265232977,
      "loss": 0.1244,
      "step": 810
    },
    {
      "epoch": 2.8349178910976662,
      "grad_norm": 0.16539046168327332,
      "learning_rate": 0.00014838709677419355,
      "loss": 0.1059,
      "step": 820
    },
    {
      "epoch": 2.8694900605012963,
      "grad_norm": 0.16092510521411896,
      "learning_rate": 0.00014767025089605735,
      "loss": 0.1,
      "step": 830
    },
    {
      "epoch": 2.904062229904927,
      "grad_norm": 0.1415339857339859,
      "learning_rate": 0.00014695340501792115,
      "loss": 0.1386,
      "step": 840
    },
    {
      "epoch": 2.9386343993085564,
      "grad_norm": 0.19023731350898743,
      "learning_rate": 0.00014623655913978496,
      "loss": 0.1182,
      "step": 850
    },
    {
      "epoch": 2.973206568712187,
      "grad_norm": 0.21056786179542542,
      "learning_rate": 0.00014551971326164876,
      "loss": 0.0988,
      "step": 860
    },
    {
      "epoch": 3.007778738115817,
      "grad_norm": 0.1848568320274353,
      "learning_rate": 0.00014480286738351254,
      "loss": 0.1398,
      "step": 870
    },
    {
      "epoch": 3.042350907519447,
      "grad_norm": 0.18773449957370758,
      "learning_rate": 0.00014408602150537637,
      "loss": 0.1301,
      "step": 880
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 0.17563946545124054,
      "learning_rate": 0.00014336917562724014,
      "loss": 0.1203,
      "step": 890
    },
    {
      "epoch": 3.111495246326707,
      "grad_norm": 0.137241929769516,
      "learning_rate": 0.00014265232974910395,
      "loss": 0.1104,
      "step": 900
    },
    {
      "epoch": 3.111495246326707,
      "eval_loss": 0.1089109554886818,
      "eval_runtime": 11.6484,
      "eval_samples_per_second": 43.955,
      "eval_steps_per_second": 5.494,
      "step": 900
    }
  ],
  "logging_steps": 10,
  "max_steps": 2890,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.658456066878341e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
