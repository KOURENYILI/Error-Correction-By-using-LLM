{
  "best_metric": 0.09475815296173096,
  "best_model_checkpoint": "wsj/checkpoint-1400",
  "epoch": 5.185825410544512,
  "eval_steps": 100,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03457216940363008,
      "grad_norm": 0.9907282590866089,
      "learning_rate": 2e-05,
      "loss": 1.8601,
      "step": 10
    },
    {
      "epoch": 0.06914433880726016,
      "grad_norm": 1.2141627073287964,
      "learning_rate": 4e-05,
      "loss": 2.0884,
      "step": 20
    },
    {
      "epoch": 0.10371650821089023,
      "grad_norm": 1.75996732711792,
      "learning_rate": 6e-05,
      "loss": 2.1985,
      "step": 30
    },
    {
      "epoch": 0.13828867761452032,
      "grad_norm": 1.3769193887710571,
      "learning_rate": 8e-05,
      "loss": 2.0919,
      "step": 40
    },
    {
      "epoch": 0.17286084701815038,
      "grad_norm": 2.67435884475708,
      "learning_rate": 0.0001,
      "loss": 2.3578,
      "step": 50
    },
    {
      "epoch": 0.20743301642178047,
      "grad_norm": 0.5522788763046265,
      "learning_rate": 0.00012,
      "loss": 0.8693,
      "step": 60
    },
    {
      "epoch": 0.24200518582541056,
      "grad_norm": 0.4029791057109833,
      "learning_rate": 0.00014,
      "loss": 0.5295,
      "step": 70
    },
    {
      "epoch": 0.27657735522904064,
      "grad_norm": 0.22140678763389587,
      "learning_rate": 0.00016,
      "loss": 0.3363,
      "step": 80
    },
    {
      "epoch": 0.3111495246326707,
      "grad_norm": 0.1841510683298111,
      "learning_rate": 0.00018,
      "loss": 0.2322,
      "step": 90
    },
    {
      "epoch": 0.34572169403630076,
      "grad_norm": 0.31985488533973694,
      "learning_rate": 0.0002,
      "loss": 0.2286,
      "step": 100
    },
    {
      "epoch": 0.34572169403630076,
      "eval_loss": 0.25413596630096436,
      "eval_runtime": 11.2132,
      "eval_samples_per_second": 45.66,
      "eval_steps_per_second": 5.708,
      "step": 100
    },
    {
      "epoch": 0.3802938634399309,
      "grad_norm": 0.14755673706531525,
      "learning_rate": 0.0001992831541218638,
      "loss": 0.3097,
      "step": 110
    },
    {
      "epoch": 0.41486603284356094,
      "grad_norm": 0.13271167874336243,
      "learning_rate": 0.00019856630824372762,
      "loss": 0.2639,
      "step": 120
    },
    {
      "epoch": 0.449438202247191,
      "grad_norm": 0.16308167576789856,
      "learning_rate": 0.00019784946236559142,
      "loss": 0.2157,
      "step": 130
    },
    {
      "epoch": 0.4840103716508211,
      "grad_norm": 0.14124096930027008,
      "learning_rate": 0.0001971326164874552,
      "loss": 0.1979,
      "step": 140
    },
    {
      "epoch": 0.5185825410544511,
      "grad_norm": 0.22106005251407623,
      "learning_rate": 0.00019641577060931903,
      "loss": 0.1796,
      "step": 150
    },
    {
      "epoch": 0.5531547104580813,
      "grad_norm": 0.13787893950939178,
      "learning_rate": 0.0001956989247311828,
      "loss": 0.2491,
      "step": 160
    },
    {
      "epoch": 0.5877268798617113,
      "grad_norm": 0.13810373842716217,
      "learning_rate": 0.0001949820788530466,
      "loss": 0.2103,
      "step": 170
    },
    {
      "epoch": 0.6222990492653414,
      "grad_norm": 0.1488470435142517,
      "learning_rate": 0.00019426523297491038,
      "loss": 0.1996,
      "step": 180
    },
    {
      "epoch": 0.6568712186689715,
      "grad_norm": 0.14719989895820618,
      "learning_rate": 0.00019354838709677422,
      "loss": 0.1774,
      "step": 190
    },
    {
      "epoch": 0.6914433880726015,
      "grad_norm": 0.37895554304122925,
      "learning_rate": 0.000192831541218638,
      "loss": 0.1525,
      "step": 200
    },
    {
      "epoch": 0.6914433880726015,
      "eval_loss": 0.17497561872005463,
      "eval_runtime": 11.219,
      "eval_samples_per_second": 45.637,
      "eval_steps_per_second": 5.705,
      "step": 200
    },
    {
      "epoch": 0.7260155574762316,
      "grad_norm": 0.13803938031196594,
      "learning_rate": 0.0001921146953405018,
      "loss": 0.2192,
      "step": 210
    },
    {
      "epoch": 0.7605877268798618,
      "grad_norm": 0.16714058816432953,
      "learning_rate": 0.0001913978494623656,
      "loss": 0.1969,
      "step": 220
    },
    {
      "epoch": 0.7951598962834918,
      "grad_norm": 0.1564909815788269,
      "learning_rate": 0.0001906810035842294,
      "loss": 0.1833,
      "step": 230
    },
    {
      "epoch": 0.8297320656871219,
      "grad_norm": 0.17892757058143616,
      "learning_rate": 0.0001899641577060932,
      "loss": 0.1493,
      "step": 240
    },
    {
      "epoch": 0.8643042350907519,
      "grad_norm": 0.3615484833717346,
      "learning_rate": 0.000189247311827957,
      "loss": 0.1458,
      "step": 250
    },
    {
      "epoch": 0.898876404494382,
      "grad_norm": 0.17339672148227692,
      "learning_rate": 0.0001885304659498208,
      "loss": 0.2065,
      "step": 260
    },
    {
      "epoch": 0.9334485738980121,
      "grad_norm": 0.16788224875926971,
      "learning_rate": 0.0001878136200716846,
      "loss": 0.1752,
      "step": 270
    },
    {
      "epoch": 0.9680207433016422,
      "grad_norm": 0.14618238806724548,
      "learning_rate": 0.0001870967741935484,
      "loss": 0.166,
      "step": 280
    },
    {
      "epoch": 1.0025929127052722,
      "grad_norm": 0.6790130734443665,
      "learning_rate": 0.0001863799283154122,
      "loss": 0.1565,
      "step": 290
    },
    {
      "epoch": 1.0371650821089022,
      "grad_norm": 0.16976338624954224,
      "learning_rate": 0.000185663082437276,
      "loss": 0.1923,
      "step": 300
    },
    {
      "epoch": 1.0371650821089022,
      "eval_loss": 0.15091872215270996,
      "eval_runtime": 32.7819,
      "eval_samples_per_second": 15.618,
      "eval_steps_per_second": 1.952,
      "step": 300
    },
    {
      "epoch": 1.0717372515125323,
      "grad_norm": 0.12104398757219315,
      "learning_rate": 0.00018494623655913978,
      "loss": 0.1828,
      "step": 310
    },
    {
      "epoch": 1.1063094209161626,
      "grad_norm": 0.12625087797641754,
      "learning_rate": 0.0001842293906810036,
      "loss": 0.1603,
      "step": 320
    },
    {
      "epoch": 1.1408815903197926,
      "grad_norm": 0.20911741256713867,
      "learning_rate": 0.00018351254480286738,
      "loss": 0.1567,
      "step": 330
    },
    {
      "epoch": 1.1754537597234227,
      "grad_norm": 0.13324372470378876,
      "learning_rate": 0.0001827956989247312,
      "loss": 0.129,
      "step": 340
    },
    {
      "epoch": 1.2100259291270528,
      "grad_norm": 0.14079585671424866,
      "learning_rate": 0.000182078853046595,
      "loss": 0.1886,
      "step": 350
    },
    {
      "epoch": 1.2445980985306828,
      "grad_norm": 0.16042180359363556,
      "learning_rate": 0.0001813620071684588,
      "loss": 0.1733,
      "step": 360
    },
    {
      "epoch": 1.2791702679343129,
      "grad_norm": 0.16367019712924957,
      "learning_rate": 0.00018064516129032257,
      "loss": 0.1462,
      "step": 370
    },
    {
      "epoch": 1.313742437337943,
      "grad_norm": 0.16483931243419647,
      "learning_rate": 0.0001799283154121864,
      "loss": 0.1283,
      "step": 380
    },
    {
      "epoch": 1.348314606741573,
      "grad_norm": 0.2594800293445587,
      "learning_rate": 0.00017921146953405018,
      "loss": 0.1265,
      "step": 390
    },
    {
      "epoch": 1.382886776145203,
      "grad_norm": 0.1620560586452484,
      "learning_rate": 0.00017849462365591398,
      "loss": 0.1795,
      "step": 400
    },
    {
      "epoch": 1.382886776145203,
      "eval_loss": 0.13690055906772614,
      "eval_runtime": 33.1849,
      "eval_samples_per_second": 15.429,
      "eval_steps_per_second": 1.929,
      "step": 400
    },
    {
      "epoch": 1.4174589455488331,
      "grad_norm": 0.18305347859859467,
      "learning_rate": 0.00017777777777777779,
      "loss": 0.1661,
      "step": 410
    },
    {
      "epoch": 1.4520311149524634,
      "grad_norm": 0.17671069502830505,
      "learning_rate": 0.0001770609318996416,
      "loss": 0.1522,
      "step": 420
    },
    {
      "epoch": 1.4866032843560935,
      "grad_norm": 0.2422553151845932,
      "learning_rate": 0.0001763440860215054,
      "loss": 0.1342,
      "step": 430
    },
    {
      "epoch": 1.5211754537597235,
      "grad_norm": 0.28758469223976135,
      "learning_rate": 0.00017562724014336917,
      "loss": 0.129,
      "step": 440
    },
    {
      "epoch": 1.5557476231633536,
      "grad_norm": 0.1343555450439453,
      "learning_rate": 0.000174910394265233,
      "loss": 0.1731,
      "step": 450
    },
    {
      "epoch": 1.5903197925669836,
      "grad_norm": 0.12750230729579926,
      "learning_rate": 0.00017419354838709678,
      "loss": 0.1581,
      "step": 460
    },
    {
      "epoch": 1.6248919619706137,
      "grad_norm": 0.18028199672698975,
      "learning_rate": 0.00017347670250896058,
      "loss": 0.1534,
      "step": 470
    },
    {
      "epoch": 1.6594641313742438,
      "grad_norm": 0.19946512579917908,
      "learning_rate": 0.00017275985663082438,
      "loss": 0.1338,
      "step": 480
    },
    {
      "epoch": 1.6940363007778738,
      "grad_norm": 0.19135929644107819,
      "learning_rate": 0.0001720430107526882,
      "loss": 0.1061,
      "step": 490
    },
    {
      "epoch": 1.7286084701815039,
      "grad_norm": 0.14309100806713104,
      "learning_rate": 0.00017132616487455196,
      "loss": 0.1668,
      "step": 500
    },
    {
      "epoch": 1.7286084701815039,
      "eval_loss": 0.1264881044626236,
      "eval_runtime": 32.7426,
      "eval_samples_per_second": 15.637,
      "eval_steps_per_second": 1.955,
      "step": 500
    },
    {
      "epoch": 1.763180639585134,
      "grad_norm": 0.1989244669675827,
      "learning_rate": 0.00017060931899641577,
      "loss": 0.145,
      "step": 510
    },
    {
      "epoch": 1.797752808988764,
      "grad_norm": 0.17411097884178162,
      "learning_rate": 0.00016989247311827957,
      "loss": 0.1404,
      "step": 520
    },
    {
      "epoch": 1.832324978392394,
      "grad_norm": 0.22678467631340027,
      "learning_rate": 0.00016917562724014338,
      "loss": 0.1331,
      "step": 530
    },
    {
      "epoch": 1.8668971477960241,
      "grad_norm": 0.21379689872264862,
      "learning_rate": 0.00016845878136200718,
      "loss": 0.1132,
      "step": 540
    },
    {
      "epoch": 1.9014693171996542,
      "grad_norm": 0.1589822769165039,
      "learning_rate": 0.00016774193548387098,
      "loss": 0.1668,
      "step": 550
    },
    {
      "epoch": 1.9360414866032842,
      "grad_norm": 0.1858605444431305,
      "learning_rate": 0.00016702508960573479,
      "loss": 0.1508,
      "step": 560
    },
    {
      "epoch": 1.9706136560069143,
      "grad_norm": 0.18468812108039856,
      "learning_rate": 0.00016630824372759856,
      "loss": 0.1305,
      "step": 570
    },
    {
      "epoch": 2.0051858254105444,
      "grad_norm": 0.20674997568130493,
      "learning_rate": 0.0001655913978494624,
      "loss": 0.1336,
      "step": 580
    },
    {
      "epoch": 2.0397579948141744,
      "grad_norm": 0.14865423738956451,
      "learning_rate": 0.00016487455197132617,
      "loss": 0.1452,
      "step": 590
    },
    {
      "epoch": 2.0743301642178045,
      "grad_norm": 0.11810127645730972,
      "learning_rate": 0.00016415770609318997,
      "loss": 0.1316,
      "step": 600
    },
    {
      "epoch": 2.0743301642178045,
      "eval_loss": 0.12203250825405121,
      "eval_runtime": 11.2813,
      "eval_samples_per_second": 45.385,
      "eval_steps_per_second": 5.673,
      "step": 600
    },
    {
      "epoch": 2.1089023336214345,
      "grad_norm": 0.15524710714817047,
      "learning_rate": 0.00016344086021505378,
      "loss": 0.1412,
      "step": 610
    },
    {
      "epoch": 2.1434745030250646,
      "grad_norm": 0.17562024295330048,
      "learning_rate": 0.00016272401433691758,
      "loss": 0.1172,
      "step": 620
    },
    {
      "epoch": 2.178046672428695,
      "grad_norm": 0.20849725604057312,
      "learning_rate": 0.00016200716845878136,
      "loss": 0.1088,
      "step": 630
    },
    {
      "epoch": 2.212618841832325,
      "grad_norm": 0.14193134009838104,
      "learning_rate": 0.00016129032258064516,
      "loss": 0.1492,
      "step": 640
    },
    {
      "epoch": 2.247191011235955,
      "grad_norm": 0.1601204127073288,
      "learning_rate": 0.00016057347670250896,
      "loss": 0.1418,
      "step": 650
    },
    {
      "epoch": 2.2817631806395853,
      "grad_norm": 0.14481939375400543,
      "learning_rate": 0.00015985663082437277,
      "loss": 0.1322,
      "step": 660
    },
    {
      "epoch": 2.3163353500432153,
      "grad_norm": 0.14912089705467224,
      "learning_rate": 0.00015913978494623657,
      "loss": 0.1108,
      "step": 670
    },
    {
      "epoch": 2.3509075194468454,
      "grad_norm": 0.2382522076368332,
      "learning_rate": 0.00015842293906810038,
      "loss": 0.0955,
      "step": 680
    },
    {
      "epoch": 2.3854796888504755,
      "grad_norm": 0.1586449295282364,
      "learning_rate": 0.00015770609318996418,
      "loss": 0.1532,
      "step": 690
    },
    {
      "epoch": 2.4200518582541055,
      "grad_norm": 0.15658827126026154,
      "learning_rate": 0.00015698924731182796,
      "loss": 0.1363,
      "step": 700
    },
    {
      "epoch": 2.4200518582541055,
      "eval_loss": 0.11725915968418121,
      "eval_runtime": 11.5416,
      "eval_samples_per_second": 44.361,
      "eval_steps_per_second": 5.545,
      "step": 700
    },
    {
      "epoch": 2.4546240276577356,
      "grad_norm": 0.14713285863399506,
      "learning_rate": 0.0001562724014336918,
      "loss": 0.1262,
      "step": 710
    },
    {
      "epoch": 2.4891961970613656,
      "grad_norm": 0.15218161046504974,
      "learning_rate": 0.00015555555555555556,
      "loss": 0.1132,
      "step": 720
    },
    {
      "epoch": 2.5237683664649957,
      "grad_norm": 0.2123243808746338,
      "learning_rate": 0.00015483870967741937,
      "loss": 0.11,
      "step": 730
    },
    {
      "epoch": 2.5583405358686258,
      "grad_norm": 0.15959039330482483,
      "learning_rate": 0.00015412186379928314,
      "loss": 0.1489,
      "step": 740
    },
    {
      "epoch": 2.592912705272256,
      "grad_norm": 0.14033855497837067,
      "learning_rate": 0.00015340501792114697,
      "loss": 0.1341,
      "step": 750
    },
    {
      "epoch": 2.627484874675886,
      "grad_norm": 0.17532344162464142,
      "learning_rate": 0.00015268817204301075,
      "loss": 0.1283,
      "step": 760
    },
    {
      "epoch": 2.662057044079516,
      "grad_norm": 0.2063031792640686,
      "learning_rate": 0.00015197132616487455,
      "loss": 0.1076,
      "step": 770
    },
    {
      "epoch": 2.696629213483146,
      "grad_norm": 0.19763138890266418,
      "learning_rate": 0.00015125448028673836,
      "loss": 0.1146,
      "step": 780
    },
    {
      "epoch": 2.731201382886776,
      "grad_norm": 0.17619936168193817,
      "learning_rate": 0.00015053763440860216,
      "loss": 0.1469,
      "step": 790
    },
    {
      "epoch": 2.765773552290406,
      "grad_norm": 0.13055089116096497,
      "learning_rate": 0.00014982078853046594,
      "loss": 0.138,
      "step": 800
    },
    {
      "epoch": 2.765773552290406,
      "eval_loss": 0.11212262511253357,
      "eval_runtime": 12.3154,
      "eval_samples_per_second": 41.574,
      "eval_steps_per_second": 5.197,
      "step": 800
    },
    {
      "epoch": 2.800345721694036,
      "grad_norm": 0.16790838539600372,
      "learning_rate": 0.00014910394265232977,
      "loss": 0.1244,
      "step": 810
    },
    {
      "epoch": 2.8349178910976662,
      "grad_norm": 0.16539046168327332,
      "learning_rate": 0.00014838709677419355,
      "loss": 0.1059,
      "step": 820
    },
    {
      "epoch": 2.8694900605012963,
      "grad_norm": 0.16092510521411896,
      "learning_rate": 0.00014767025089605735,
      "loss": 0.1,
      "step": 830
    },
    {
      "epoch": 2.904062229904927,
      "grad_norm": 0.1415339857339859,
      "learning_rate": 0.00014695340501792115,
      "loss": 0.1386,
      "step": 840
    },
    {
      "epoch": 2.9386343993085564,
      "grad_norm": 0.19023731350898743,
      "learning_rate": 0.00014623655913978496,
      "loss": 0.1182,
      "step": 850
    },
    {
      "epoch": 2.973206568712187,
      "grad_norm": 0.21056786179542542,
      "learning_rate": 0.00014551971326164876,
      "loss": 0.0988,
      "step": 860
    },
    {
      "epoch": 3.007778738115817,
      "grad_norm": 0.1848568320274353,
      "learning_rate": 0.00014480286738351254,
      "loss": 0.1398,
      "step": 870
    },
    {
      "epoch": 3.042350907519447,
      "grad_norm": 0.18773449957370758,
      "learning_rate": 0.00014408602150537637,
      "loss": 0.1301,
      "step": 880
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 0.17563946545124054,
      "learning_rate": 0.00014336917562724014,
      "loss": 0.1203,
      "step": 890
    },
    {
      "epoch": 3.111495246326707,
      "grad_norm": 0.137241929769516,
      "learning_rate": 0.00014265232974910395,
      "loss": 0.1104,
      "step": 900
    },
    {
      "epoch": 3.111495246326707,
      "eval_loss": 0.1089109554886818,
      "eval_runtime": 11.6484,
      "eval_samples_per_second": 43.955,
      "eval_steps_per_second": 5.494,
      "step": 900
    },
    {
      "epoch": 3.146067415730337,
      "grad_norm": 0.2792550027370453,
      "learning_rate": 0.00014193548387096775,
      "loss": 0.0945,
      "step": 910
    },
    {
      "epoch": 3.1806395851339673,
      "grad_norm": 0.17919790744781494,
      "learning_rate": 0.00014121863799283155,
      "loss": 0.0871,
      "step": 920
    },
    {
      "epoch": 3.2152117545375973,
      "grad_norm": 0.15823107957839966,
      "learning_rate": 0.00014050179211469533,
      "loss": 0.1355,
      "step": 930
    },
    {
      "epoch": 3.2497839239412274,
      "grad_norm": 0.1567526012659073,
      "learning_rate": 0.00013978494623655916,
      "loss": 0.1195,
      "step": 940
    },
    {
      "epoch": 3.2843560933448575,
      "grad_norm": 0.2357216775417328,
      "learning_rate": 0.00013906810035842294,
      "loss": 0.1081,
      "step": 950
    },
    {
      "epoch": 3.3189282627484875,
      "grad_norm": 0.1854330152273178,
      "learning_rate": 0.00013835125448028674,
      "loss": 0.0887,
      "step": 960
    },
    {
      "epoch": 3.3535004321521176,
      "grad_norm": 0.2061859518289566,
      "learning_rate": 0.00013763440860215055,
      "loss": 0.1055,
      "step": 970
    },
    {
      "epoch": 3.3880726015557476,
      "grad_norm": 0.1976693570613861,
      "learning_rate": 0.00013691756272401435,
      "loss": 0.1167,
      "step": 980
    },
    {
      "epoch": 3.4226447709593777,
      "grad_norm": 0.18041954934597015,
      "learning_rate": 0.00013620071684587815,
      "loss": 0.1081,
      "step": 990
    },
    {
      "epoch": 3.4572169403630078,
      "grad_norm": 0.18821954727172852,
      "learning_rate": 0.00013548387096774193,
      "loss": 0.108,
      "step": 1000
    },
    {
      "epoch": 3.4572169403630078,
      "eval_loss": 0.10602235049009323,
      "eval_runtime": 11.9784,
      "eval_samples_per_second": 42.744,
      "eval_steps_per_second": 5.343,
      "step": 1000
    },
    {
      "epoch": 3.491789109766638,
      "grad_norm": 0.2278793305158615,
      "learning_rate": 0.00013476702508960576,
      "loss": 0.098,
      "step": 1010
    },
    {
      "epoch": 3.526361279170268,
      "grad_norm": 0.16616380214691162,
      "learning_rate": 0.00013405017921146954,
      "loss": 0.0878,
      "step": 1020
    },
    {
      "epoch": 3.560933448573898,
      "grad_norm": 0.15953217446804047,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.131,
      "step": 1030
    },
    {
      "epoch": 3.595505617977528,
      "grad_norm": 0.25272735953330994,
      "learning_rate": 0.00013261648745519714,
      "loss": 0.1225,
      "step": 1040
    },
    {
      "epoch": 3.630077787381158,
      "grad_norm": 0.19466306269168854,
      "learning_rate": 0.00013189964157706095,
      "loss": 0.1136,
      "step": 1050
    },
    {
      "epoch": 3.664649956784788,
      "grad_norm": 0.3144766688346863,
      "learning_rate": 0.00013118279569892472,
      "loss": 0.0863,
      "step": 1060
    },
    {
      "epoch": 3.699222126188418,
      "grad_norm": 0.18299204111099243,
      "learning_rate": 0.00013046594982078855,
      "loss": 0.0864,
      "step": 1070
    },
    {
      "epoch": 3.7337942955920482,
      "grad_norm": 0.18562796711921692,
      "learning_rate": 0.00012974910394265233,
      "loss": 0.1355,
      "step": 1080
    },
    {
      "epoch": 3.7683664649956787,
      "grad_norm": 0.20743203163146973,
      "learning_rate": 0.00012903225806451613,
      "loss": 0.1219,
      "step": 1090
    },
    {
      "epoch": 3.8029386343993083,
      "grad_norm": 0.2046847939491272,
      "learning_rate": 0.0001283154121863799,
      "loss": 0.1103,
      "step": 1100
    },
    {
      "epoch": 3.8029386343993083,
      "eval_loss": 0.1026148647069931,
      "eval_runtime": 13.2202,
      "eval_samples_per_second": 38.729,
      "eval_steps_per_second": 4.841,
      "step": 1100
    },
    {
      "epoch": 3.837510803802939,
      "grad_norm": 0.21793951094150543,
      "learning_rate": 0.00012759856630824374,
      "loss": 0.0951,
      "step": 1110
    },
    {
      "epoch": 3.8720829732065685,
      "grad_norm": 0.2382974773645401,
      "learning_rate": 0.00012688172043010752,
      "loss": 0.0843,
      "step": 1120
    },
    {
      "epoch": 3.906655142610199,
      "grad_norm": 0.1763051450252533,
      "learning_rate": 0.00012616487455197132,
      "loss": 0.1215,
      "step": 1130
    },
    {
      "epoch": 3.941227312013829,
      "grad_norm": 0.20589306950569153,
      "learning_rate": 0.00012544802867383513,
      "loss": 0.1174,
      "step": 1140
    },
    {
      "epoch": 3.975799481417459,
      "grad_norm": 0.20010626316070557,
      "learning_rate": 0.00012473118279569893,
      "loss": 0.0912,
      "step": 1150
    },
    {
      "epoch": 4.010371650821089,
      "grad_norm": 0.19143171608448029,
      "learning_rate": 0.00012401433691756273,
      "loss": 0.094,
      "step": 1160
    },
    {
      "epoch": 4.044943820224719,
      "grad_norm": 0.15890279412269592,
      "learning_rate": 0.00012329749103942654,
      "loss": 0.1177,
      "step": 1170
    },
    {
      "epoch": 4.079515989628349,
      "grad_norm": 0.1650223433971405,
      "learning_rate": 0.00012258064516129034,
      "loss": 0.0977,
      "step": 1180
    },
    {
      "epoch": 4.114088159031979,
      "grad_norm": 0.20625343918800354,
      "learning_rate": 0.00012186379928315412,
      "loss": 0.0932,
      "step": 1190
    },
    {
      "epoch": 4.148660328435609,
      "grad_norm": 0.18307577073574066,
      "learning_rate": 0.00012114695340501793,
      "loss": 0.0794,
      "step": 1200
    },
    {
      "epoch": 4.148660328435609,
      "eval_loss": 0.0997045487165451,
      "eval_runtime": 12.1825,
      "eval_samples_per_second": 42.027,
      "eval_steps_per_second": 5.253,
      "step": 1200
    },
    {
      "epoch": 4.1832324978392394,
      "grad_norm": 0.1866925060749054,
      "learning_rate": 0.00012043010752688172,
      "loss": 0.0757,
      "step": 1210
    },
    {
      "epoch": 4.217804667242869,
      "grad_norm": 0.16962388157844543,
      "learning_rate": 0.00011971326164874553,
      "loss": 0.1148,
      "step": 1220
    },
    {
      "epoch": 4.2523768366465,
      "grad_norm": 0.1579330563545227,
      "learning_rate": 0.00011899641577060932,
      "loss": 0.1015,
      "step": 1230
    },
    {
      "epoch": 4.286949006050129,
      "grad_norm": 0.18235692381858826,
      "learning_rate": 0.00011827956989247313,
      "loss": 0.0931,
      "step": 1240
    },
    {
      "epoch": 4.32152117545376,
      "grad_norm": 0.2933397889137268,
      "learning_rate": 0.00011756272401433692,
      "loss": 0.0831,
      "step": 1250
    },
    {
      "epoch": 4.35609334485739,
      "grad_norm": 0.21949422359466553,
      "learning_rate": 0.00011684587813620071,
      "loss": 0.0782,
      "step": 1260
    },
    {
      "epoch": 4.39066551426102,
      "grad_norm": 0.17023859918117523,
      "learning_rate": 0.00011612903225806453,
      "loss": 0.1082,
      "step": 1270
    },
    {
      "epoch": 4.42523768366465,
      "grad_norm": 0.228946253657341,
      "learning_rate": 0.00011541218637992832,
      "loss": 0.0988,
      "step": 1280
    },
    {
      "epoch": 4.45980985306828,
      "grad_norm": 0.18495921790599823,
      "learning_rate": 0.00011469534050179211,
      "loss": 0.0972,
      "step": 1290
    },
    {
      "epoch": 4.49438202247191,
      "grad_norm": 0.24620158970355988,
      "learning_rate": 0.00011397849462365593,
      "loss": 0.075,
      "step": 1300
    },
    {
      "epoch": 4.49438202247191,
      "eval_loss": 0.09823976457118988,
      "eval_runtime": 11.3864,
      "eval_samples_per_second": 44.966,
      "eval_steps_per_second": 5.621,
      "step": 1300
    },
    {
      "epoch": 4.52895419187554,
      "grad_norm": 0.18089322745800018,
      "learning_rate": 0.00011326164874551972,
      "loss": 0.0788,
      "step": 1310
    },
    {
      "epoch": 4.5635263612791706,
      "grad_norm": 0.24444618821144104,
      "learning_rate": 0.00011254480286738351,
      "loss": 0.115,
      "step": 1320
    },
    {
      "epoch": 4.5980985306828,
      "grad_norm": 0.1853044033050537,
      "learning_rate": 0.00011182795698924731,
      "loss": 0.1126,
      "step": 1330
    },
    {
      "epoch": 4.632670700086431,
      "grad_norm": 0.1509925276041031,
      "learning_rate": 0.00011111111111111112,
      "loss": 0.0968,
      "step": 1340
    },
    {
      "epoch": 4.66724286949006,
      "grad_norm": 0.237075075507164,
      "learning_rate": 0.00011039426523297492,
      "loss": 0.0791,
      "step": 1350
    },
    {
      "epoch": 4.701815038893691,
      "grad_norm": 0.20207270979881287,
      "learning_rate": 0.00010967741935483871,
      "loss": 0.0884,
      "step": 1360
    },
    {
      "epoch": 4.73638720829732,
      "grad_norm": 0.16342666745185852,
      "learning_rate": 0.00010896057347670253,
      "loss": 0.1113,
      "step": 1370
    },
    {
      "epoch": 4.770959377700951,
      "grad_norm": 0.18191660940647125,
      "learning_rate": 0.00010824372759856632,
      "loss": 0.1026,
      "step": 1380
    },
    {
      "epoch": 4.8055315471045805,
      "grad_norm": 0.18099527060985565,
      "learning_rate": 0.00010752688172043011,
      "loss": 0.0989,
      "step": 1390
    },
    {
      "epoch": 4.840103716508211,
      "grad_norm": 0.2286798059940338,
      "learning_rate": 0.00010681003584229392,
      "loss": 0.0836,
      "step": 1400
    },
    {
      "epoch": 4.840103716508211,
      "eval_loss": 0.09475815296173096,
      "eval_runtime": 11.6963,
      "eval_samples_per_second": 43.774,
      "eval_steps_per_second": 5.472,
      "step": 1400
    },
    {
      "epoch": 4.874675885911841,
      "grad_norm": 0.2073305994272232,
      "learning_rate": 0.00010609318996415771,
      "loss": 0.0777,
      "step": 1410
    },
    {
      "epoch": 4.909248055315471,
      "grad_norm": 0.29049569368362427,
      "learning_rate": 0.0001053763440860215,
      "loss": 0.1143,
      "step": 1420
    },
    {
      "epoch": 4.943820224719101,
      "grad_norm": 0.1683259755373001,
      "learning_rate": 0.00010465949820788532,
      "loss": 0.1018,
      "step": 1430
    },
    {
      "epoch": 4.978392394122731,
      "grad_norm": 0.17810502648353577,
      "learning_rate": 0.00010394265232974911,
      "loss": 0.0708,
      "step": 1440
    },
    {
      "epoch": 5.012964563526361,
      "grad_norm": 0.14642034471035004,
      "learning_rate": 0.0001032258064516129,
      "loss": 0.0827,
      "step": 1450
    },
    {
      "epoch": 5.047536732929991,
      "grad_norm": 0.13633520901203156,
      "learning_rate": 0.00010250896057347669,
      "loss": 0.0955,
      "step": 1460
    },
    {
      "epoch": 5.082108902333621,
      "grad_norm": 0.14258214831352234,
      "learning_rate": 0.00010179211469534051,
      "loss": 0.0961,
      "step": 1470
    },
    {
      "epoch": 5.1166810717372515,
      "grad_norm": 0.21459822356700897,
      "learning_rate": 0.0001010752688172043,
      "loss": 0.0797,
      "step": 1480
    },
    {
      "epoch": 5.151253241140882,
      "grad_norm": 0.20159563422203064,
      "learning_rate": 0.0001003584229390681,
      "loss": 0.0748,
      "step": 1490
    },
    {
      "epoch": 5.185825410544512,
      "grad_norm": 0.19654963910579681,
      "learning_rate": 9.96415770609319e-05,
      "loss": 0.075,
      "step": 1500
    },
    {
      "epoch": 5.185825410544512,
      "eval_loss": 0.09504197537899017,
      "eval_runtime": 11.7994,
      "eval_samples_per_second": 43.392,
      "eval_steps_per_second": 5.424,
      "step": 1500
    }
  ],
  "logging_steps": 10,
  "max_steps": 2890,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.7548476262527795e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
